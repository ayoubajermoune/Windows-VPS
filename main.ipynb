{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoubajermoune/Windows-VPS/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRk_fIeNbXOg",
        "outputId": "2bf08a31-9ddf-464f-a4ad-e8c98fda77d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.19.0-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.25.0-py3-none-any.whl (467 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m467.2/467.2 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.9->selenium)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
            "Successfully installed h11-0.14.0 outcome-1.3.0.post0 selenium-4.19.0 trio-0.25.0 trio-websocket-0.11.1 wsproto-1.2.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,082 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,695 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,375 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [51.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,975 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [2,242 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:14 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:16 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 8,654 kB in 4s (2,088 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  apparmor chromium-browser libfuse3-3 liblzo2-2 libudev1 snapd squashfs-tools systemd-hwe-hwdb\n",
            "  udev\n",
            "Suggested packages:\n",
            "  apparmor-profiles-extra apparmor-utils fuse3 zenity | kdialog\n",
            "The following NEW packages will be installed:\n",
            "  apparmor chromium-browser chromium-chromedriver libfuse3-3 liblzo2-2 snapd squashfs-tools\n",
            "  systemd-hwe-hwdb udev\n",
            "The following packages will be upgraded:\n",
            "  libudev1\n",
            "1 upgraded, 9 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 27.3 MB of archives.\n",
            "After this operation, 114 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 apparmor amd64 3.0.4-2ubuntu2.3 [595 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblzo2-2 amd64 2.10-2build3 [53.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 squashfs-tools amd64 1:4.5-3build1 [159 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.12 [78.2 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.12 [1,557 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfuse3-3 amd64 3.10.5-1build1 [81.2 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 snapd amd64 2.61.3+22.04 [24.7 MB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-browser amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [49.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 chromium-chromedriver amd64 1:85.0.4183.83-0ubuntu2.22.04.1 [2,308 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\n",
            "Fetched 27.3 MB in 2s (13.9 MB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package apparmor.\n",
            "(Reading database ... 121752 files and directories currently installed.)\n",
            "Preparing to unpack .../apparmor_3.0.4-2ubuntu2.3_amd64.deb ...\n",
            "Unpacking apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Selecting previously unselected package liblzo2-2:amd64.\n",
            "Preparing to unpack .../liblzo2-2_2.10-2build3_amd64.deb ...\n",
            "Unpacking liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Selecting previously unselected package squashfs-tools.\n",
            "Preparing to unpack .../squashfs-tools_1%3a4.5-3build1_amd64.deb ...\n",
            "Unpacking squashfs-tools (1:4.5-3build1) ...\n",
            "Preparing to unpack .../libudev1_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking libudev1:amd64 (249.11-0ubuntu3.12) over (249.11-0ubuntu3.10) ...\n",
            "Setting up libudev1:amd64 (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package udev.\n",
            "(Reading database ... 121960 files and directories currently installed.)\n",
            "Preparing to unpack .../udev_249.11-0ubuntu3.12_amd64.deb ...\n",
            "Unpacking udev (249.11-0ubuntu3.12) ...\n",
            "Selecting previously unselected package libfuse3-3:amd64.\n",
            "Preparing to unpack .../libfuse3-3_3.10.5-1build1_amd64.deb ...\n",
            "Unpacking libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Selecting previously unselected package snapd.\n",
            "Preparing to unpack .../snapd_2.61.3+22.04_amd64.deb ...\n",
            "Unpacking snapd (2.61.3+22.04) ...\n",
            "Setting up apparmor (3.0.4-2ubuntu2.3) ...\n",
            "Created symlink /etc/systemd/system/sysinit.target.wants/apparmor.service → /lib/systemd/system/apparmor.service.\n",
            "Setting up liblzo2-2:amd64 (2.10-2build3) ...\n",
            "Setting up squashfs-tools (1:4.5-3build1) ...\n",
            "Setting up udev (249.11-0ubuntu3.12) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up libfuse3-3:amd64 (3.10.5-1build1) ...\n",
            "Setting up snapd (2.61.3+22.04) ...\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.apparmor.service → /lib/systemd/system/snapd.apparmor.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.autoimport.service → /lib/systemd/system/snapd.autoimport.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.core-fixup.service → /lib/systemd/system/snapd.core-fixup.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.recovery-chooser-trigger.service → /lib/systemd/system/snapd.recovery-chooser-trigger.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Created symlink /etc/systemd/system/cloud-final.service.wants/snapd.seeded.service → /lib/systemd/system/snapd.seeded.service.\n",
            "Unit /lib/systemd/system/snapd.seeded.service is added as a dependency to a non-existent unit cloud-final.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/snapd.service → /lib/systemd/system/snapd.service.\n",
            "Created symlink /etc/systemd/system/timers.target.wants/snapd.snap-repair.timer → /lib/systemd/system/snapd.snap-repair.timer.\n",
            "Created symlink /etc/systemd/system/sockets.target.wants/snapd.socket → /lib/systemd/system/snapd.socket.\n",
            "Created symlink /etc/systemd/system/final.target.wants/snapd.system-shutdown.service → /lib/systemd/system/snapd.system-shutdown.service.\n",
            "Selecting previously unselected package chromium-browser.\n",
            "(Reading database ... 122190 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-browser_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "=> Installing the chromium snap\n",
            "==> Checking connectivity with the snap store\n",
            "===> System doesn't have a working snapd, skipping\n",
            "Unpacking chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_1%3a85.0.4183.83-0ubuntu2.22.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Selecting previously unselected package systemd-hwe-hwdb.\n",
            "Preparing to unpack .../systemd-hwe-hwdb_249.11.5_all.deb ...\n",
            "Unpacking systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up systemd-hwe-hwdb (249.11.5) ...\n",
            "Setting up chromium-browser (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (1:85.0.4183.83-0ubuntu2.22.04.1) ...\n",
            "Processing triggers for udev (249.11-0ubuntu3.12) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for dbus (1.12.20-2ubuntu4.1) ...\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "_RUqJd6rfuB1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NpSgC7ajbiX2"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "traders_list = []\n",
        "def dianmic_webset():\n",
        "    url_list = ['https://my.litefinance.org/traders?type=profit', 'https://my.litefinance.org/traders?type=risk']\n",
        "    for url in url_list:\n",
        "        browser.get(url)\n",
        "        for _ in range(1):\n",
        "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(1)\n",
        "        content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "        traders = content.find_all('div' , {'class' : 'card_trader'})\n",
        "        for trader in traders:\n",
        "          profitability = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "          profitability = profitability.text.strip().replace('%', '')\n",
        "          if float(profitability) >= 10:\n",
        "            user_info = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'title'})\n",
        "            id = trader.find('a' , {'class' : 'link'}).get('href')\n",
        "            result = {\n",
        "                'trader name': user_info.text.strip(),\n",
        "                'id': id.strip().replace('/traders/info?id=', ''),\n",
        "                'Profitability (All time) %' : profitability\n",
        "            }\n",
        "            traders_list.append(result)\n",
        "    with open('traders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['trader name', 'id' , 'Profitability (All time) %']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for trader in traders_list:\n",
        "            writer.writerow(trader)\n",
        "dianmic_webset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GIY87wNfFK9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def annual_rates(id:int,path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        detail_chart_range = content.find('div' , {'class' : 'trader_detail_chart'})\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[0].find_all('div' , {'class' : 'bar'})\n",
        "        Date = []\n",
        "        for bar in bars:\n",
        "          date = bar.find('div' , {'class' : 'data_label'}).text.strip().replace(' ','').replace('\\n' , ' ').split()\n",
        "          date = ' '.join(date[1:3])\n",
        "          result = {\n",
        "              'Date':date\n",
        "          }\n",
        "          Date.append(result)\n",
        "\n",
        "        Profitability = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('%' , '')\n",
        "          result = {\n",
        "              'Profitability %' : value\n",
        "          }\n",
        "          Profitability.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[1].find_all('div' , {'class' : 'bar'})\n",
        "        Risk = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('risk' , '')\n",
        "          result = {\n",
        "              'Risk' : value\n",
        "          }\n",
        "          Risk.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[2].find_all('div' , {'class' : 'bar'})\n",
        "        Copying = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip()\n",
        "          result = {\n",
        "              'Copying' : value\n",
        "          }\n",
        "          Copying.append(result)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Date': Date,\n",
        "            'Risk': Risk,\n",
        "            'Copying': Copying,\n",
        "            'Profitability %': Profitability\n",
        "        })\n",
        "\n",
        "        # Format Date column\n",
        "        df['Date'] = df['Date'].apply(lambda x: x['Date'])\n",
        "        df['Risk'] = df['Risk'].apply(lambda x: x['Risk'])\n",
        "        df['Copying'] = df['Copying'].apply(lambda x: x['Copying'])\n",
        "        df['Profitability %'] = df['Profitability %'].apply(lambda x: x['Profitability %'])\n",
        "\n",
        "\n",
        "        # Set Date as index\n",
        "        df.set_index('Date', inplace=True)\n",
        "\n",
        "        # Write DataFrame to CSV\n",
        "        csv_file = f\"{path}/annual rates.csv\"\n",
        "        df.to_csv(csv_file)\n"
      ],
      "metadata": {
        "id": "r3zqm9aPfniJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def popular_tools(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail_tools = content.find_all('div', {'class': 'panel_inner'})[2]\n",
        "        content_row = trader_detail_tools.find_all('div', {'class': 'content_row_inner'})\n",
        "        detail_tools = []\n",
        "        for row in content_row:\n",
        "            title = row.find('div', {'class': 'title'})\n",
        "            trades = row.find_all('div', {'class': 'data'})[1].find('div', 'data_value')\n",
        "            profitable = row.find_all('div', {'class': 'data'})[2].find('div', 'data_value')\n",
        "            result = {\n",
        "                'title': title.text.strip().replace('_o', ''),\n",
        "                'trades': trades.text.strip(),\n",
        "                'Profitable %': profitable.text.strip().replace('%', '')\n",
        "            }\n",
        "            detail_tools.append(result)\n",
        "\n",
        "        field_names = ['title', 'trades', 'Profitable %']\n",
        "        with open(f'{path}/popular tools.csv', mode='w', newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "            writer.writeheader()\n",
        "            for detail in detail_tools:\n",
        "                writer.writerow(detail)"
      ],
      "metadata": {
        "id": "LmmFje_ynmFC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Portfolio_composition(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail = content.find('div' , {'class' : 'trader_detail_tools_chart_data'}).find_all('div' , {'class' : 'data'})\n",
        "        Detail_name = []\n",
        "        Detail_value = []\n",
        "        for detail in trader_detail:\n",
        "          mareket = detail.find('div' , {'class' : 'data_label'})\n",
        "          precentage = detail.find('div' , {'class' : 'data_value'})\n",
        "          Detail_name.append(f'{mareket.text.strip()} %')\n",
        "          Detail_value.append(precentage.text.strip().replace('%', ''))\n",
        "\n",
        "        with open(f'{path}/Portfolio composition.csv', mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(Detail_name)\n",
        "            writer.writerow(Detail_value)"
      ],
      "metadata": {
        "id": "jDBKmWb4oeHT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "\n",
        "def trading_history(id:int , path:str):\n",
        "  url = f'https://my.litefinance.org/traders/trades-history?id={id}'\n",
        "  browser.get(url)\n",
        "  for _ in range(1):\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(1)\n",
        "  content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "  rows = content.find_all('div' , {'class' : 'content_row'})\n",
        "  history = []\n",
        "  for row in rows:\n",
        "    title = row.find_all('div' , {'class' : 'content_col'})[0].find('div' , {'class' : 'title'})\n",
        "    opening_time = row.find_all('div' , {'class' : 'content_col'})[1].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    closing_time = row.find_all('div' , {'class' : 'content_col'})[2].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    action = row.find_all('div' , {'class' : 'content_col'})[3].find('div' , {'class' : 'label'})\n",
        "    volume = row.find_all('div' , {'class' : 'content_col'})[4].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    entry_point = row.find_all('div' , {'class' : 'content_col'})[5].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    exit_point = row.find_all('div' , {'class' : 'content_col'})[6].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    profit = row.find_all('div' , {'class' : 'content_col'})[7].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    result = {\n",
        "        'title' : title.text.strip() ,\n",
        "        'opening time' : opening_time.text.strip(),\n",
        "        'closing time' :closing_time.text.strip() ,\n",
        "        'action' :action.text.strip() ,\n",
        "        'volume' : volume.text.strip(),\n",
        "        'entry point' : entry_point.text.strip() ,\n",
        "        'exit point' : exit_point.text.strip() ,\n",
        "        'profit (USD)' : profit.text.strip().replace(' USD','')\n",
        "    }\n",
        "    history.append(result)\n",
        "  field_names = ['title' , 'opening time' , 'closing time' , 'action' , 'volume' , 'entry point' , 'exit point' , 'profit (USD)']\n",
        "  with open(f'{path}/history.csv', mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "    writer.writeheader()\n",
        "    for hist in history:\n",
        "        writer.writerow(hist)"
      ],
      "metadata": {
        "id": "z-9STSfUpuZd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "traders = pd.read_csv('traders.csv')\n",
        "\n",
        "for index, row in traders.iterrows():\n",
        "    trader_name = row['trader name']\n",
        "    trader_id = row['id']\n",
        "    new_folder_path = f'/content/traders info/{trader_name}'\n",
        "    try:\n",
        "      os.makedirs(new_folder_path)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "    #annual_rates(id =trader_id , path = f'{new_folder_path}')\n",
        "#\n",
        "    #popular_tools(id =trader_id , path = f'{new_folder_path}')\n",
        "#\n",
        "    #Portfolio_composition(id =trader_id , path = f'{new_folder_path}')\n",
        "\n",
        "    trading_history(id =trader_id , path = f'{new_folder_path}')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QEHApJvDgd0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-btXA5oHgrSf"
      },
      "execution_count": 7,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6EfHU/fKvHhxq2DXK+wIY",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}