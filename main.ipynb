{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoubajermoune/Windows-VPS/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRk_fIeNbXOg"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "_RUqJd6rfuB1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "NpSgC7ajbiX2"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "traders_list = []\n",
        "def dianmic_webset():\n",
        "    url_list = ['https://my.litefinance.org/traders?type=profit', 'https://my.litefinance.org/traders?type=risk']\n",
        "    for url in url_list:\n",
        "        browser.get(url)\n",
        "        for _ in range(1):\n",
        "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(1)\n",
        "        content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "        traders = content.find_all('div' , {'class' : 'card_trader'})\n",
        "        for trader in traders:\n",
        "          profitability = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "          profitability = profitability.text.strip().replace('%', '')\n",
        "          if float(profitability) >= 50:\n",
        "            user_info = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'title'})\n",
        "            id = trader.find('a' , {'class' : 'link'}).get('href')\n",
        "            result = {\n",
        "                'trader name': user_info.text.strip(),\n",
        "                'id': id.strip().replace('/traders/info?id=', ''),\n",
        "                'Profitability (All time) %' : profitability\n",
        "            }\n",
        "            traders_list.append(result)\n",
        "    with open('traders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['trader name', 'id' , 'Profitability (All time) %']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for trader in traders_list:\n",
        "            writer.writerow(trader)\n",
        "dianmic_webset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def annual_rates(id:int,path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        detail_chart_range = content.find('div' , {'class' : 'trader_detail_chart'})\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[0].find_all('div' , {'class' : 'bar'})\n",
        "        Date = []\n",
        "        for bar in bars:\n",
        "          date = bar.find('div' , {'class' : 'data_label'}).text.strip().replace(' ','').replace('\\n' , ' ').split()\n",
        "          date = ' '.join(date[1:3])\n",
        "          result = {\n",
        "              'Date':date\n",
        "          }\n",
        "          Date.append(result)\n",
        "\n",
        "        Profitability = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('%' , '')\n",
        "          result = {\n",
        "              'Profitability %' : value\n",
        "          }\n",
        "          Profitability.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[1].find_all('div' , {'class' : 'bar'})\n",
        "        Risk = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('risk' , '')\n",
        "          result = {\n",
        "              'Risk' : value\n",
        "          }\n",
        "          Risk.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[2].find_all('div' , {'class' : 'bar'})\n",
        "        Copying = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip()\n",
        "          result = {\n",
        "              'Copying' : value\n",
        "          }\n",
        "          Copying.append(result)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Date': Date,\n",
        "            'Risk': Risk,\n",
        "            'Copying': Copying,\n",
        "            'Profitability %': Profitability\n",
        "        })\n",
        "\n",
        "        df['Date'] = df['Date'].apply(lambda x: x['Date'])\n",
        "        df['Risk'] = df['Risk'].apply(lambda x: x['Risk'])\n",
        "        df['Copying'] = df['Copying'].apply(lambda x: x['Copying'])\n",
        "        df['Profitability %'] = df['Profitability %'].apply(lambda x: x['Profitability %'])\n",
        "\n",
        "        df.set_index('Date', inplace=True)\n",
        "\n",
        "        csv_file = f\"{path}/annual rates.csv\"\n",
        "        df.to_csv(csv_file)"
      ],
      "metadata": {
        "id": "r3zqm9aPfniJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def popular_tools(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail_tools = content.find_all('div', {'class': 'panel_inner'})[2]\n",
        "        content_row = trader_detail_tools.find_all('div', {'class': 'content_row_inner'})\n",
        "        detail_tools = []\n",
        "        for row in content_row:\n",
        "          profitable_tag = row.find_all('div', {'class': 'data'})[2].find('div', 'data_value')\n",
        "          profitable = profitable_tag.text.strip().replace('%', '')\n",
        "          if float(profitable) >= 70:\n",
        "            title = row.find('div', {'class': 'title'})\n",
        "            trades = row.find_all('div', {'class': 'data'})[1].find('div', 'data_value')\n",
        "            result = {\n",
        "                'title': title.text.strip().replace('_o', '')[:6],\n",
        "                'trades': trades.text.strip(),\n",
        "                'Profitable %': profitable\n",
        "            }\n",
        "            detail_tools.append(result)\n",
        "\n",
        "        field_names = ['title', 'trades', 'Profitable %']\n",
        "        with open(f'{path}/popular tools.csv', mode='w', newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "            writer.writeheader()\n",
        "            for detail in detail_tools:\n",
        "                writer.writerow(detail)"
      ],
      "metadata": {
        "id": "LmmFje_ynmFC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Portfolio_composition(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail = content.find('div' , {'class' : 'trader_detail_tools_chart_data'}).find_all('div' , {'class' : 'data'})\n",
        "        Detail_name = []\n",
        "        Detail_value = []\n",
        "        for detail in trader_detail:\n",
        "          mareket = detail.find('div' , {'class' : 'data_label'})\n",
        "          precentage = detail.find('div' , {'class' : 'data_value'})\n",
        "          Detail_name.append(f'{mareket.text.strip()} %')\n",
        "          Detail_value.append(precentage.text.strip().replace('%', ''))\n",
        "\n",
        "        with open(f'{path}/Portfolio composition.csv', mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(Detail_name)\n",
        "            writer.writerow(Detail_value)"
      ],
      "metadata": {
        "id": "jDBKmWb4oeHT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "\n",
        "def trading_history(id:int , path:str , currency : list):\n",
        "  url = f'https://my.litefinance.org/traders/trades-history?id={id}'\n",
        "  browser.get(url)\n",
        "  for _ in range(1):\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(1)\n",
        "  content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "  rows = content.find_all('div' , {'class' : 'content_row'})\n",
        "  history = []\n",
        "  for row in rows:\n",
        "    title = row.find_all('div' , {'class' : 'content_col'})[0].find('div' , {'class' : 'title'})\n",
        "    title = title.text.strip()\n",
        "    for symbol in currency:\n",
        "      if symbol == title:\n",
        "        opening_time = row.find_all('div' , {'class' : 'content_col'})[1].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        closing_time = row.find_all('div' , {'class' : 'content_col'})[2].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        action = row.find_all('div' , {'class' : 'content_col'})[3].find('div' , {'class' : 'label'})\n",
        "        volume = row.find_all('div' , {'class' : 'content_col'})[4].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        entry_point = row.find_all('div' , {'class' : 'content_col'})[5].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        exit_point = row.find_all('div' , {'class' : 'content_col'})[6].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        profit = row.find_all('div' , {'class' : 'content_col'})[7].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        profit = profit.text.strip().replace(' USD','').replace(' ','').replace('\\xa0', '')\n",
        "        result = {\n",
        "            'title' : title ,\n",
        "            'opening time' : opening_time.text.strip(),\n",
        "            'closing time' :closing_time.text.strip() ,\n",
        "            'action' :action.text.strip() ,\n",
        "            'volume' : volume.text.strip(),\n",
        "            'entry point' : entry_point.text.strip() ,\n",
        "            'exit point' : exit_point.text.strip() ,\n",
        "            'profit (USD)' : float(profit)\n",
        "        }\n",
        "        history.append(result)\n",
        "\n",
        "  field_names = ['title' , 'opening time' , 'closing time' , 'action' , 'volume' , 'entry point' , 'exit point' , 'profit (USD)']\n",
        "  with open(f'{path}/history.csv', mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "    writer.writeheader()\n",
        "    for hist in history:\n",
        "        writer.writerow(hist)"
      ],
      "metadata": {
        "id": "z-9STSfUpuZd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def Get_info_for_trader(id:int , path:str):\n",
        "  url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "  r = requests.get(url_trader)\n",
        "  if r.status_code == 200:\n",
        "    content = BeautifulSoup(r.text , 'html.parser')\n",
        "    tradre_name = content.find('div' , {'class' : 'title'})\n",
        "    panel_inner = content.find_all('div' , {'class' : 'panel_inner'})[0]\n",
        "    country = panel_inner.find_all('div' , {'class' : 'data'})[0].find('div' , {'class' : 'data_value'})\n",
        "    in_ranking = panel_inner.find_all('div' , {'class' : 'data'})[1].find('div' , {'class' : 'data_value'})\n",
        "    personal_assets = panel_inner.find_all('div' , {'class' : 'data'})[2].find('div' , {'class' : 'data_value'})\n",
        "    copy_traders_assets = panel_inner.find_all('div' , {'class' : 'data'})[3].find('div' , {'class' : 'data_value'})\n",
        "    number_of_copy_traders = panel_inner.find_all('div' , {'class' : 'data'})[4].find('div' , {'class' : 'data_value'})\n",
        "    risk = panel_inner.find_all('div' , {'class' : 'data'})[5].find('span')\n",
        "    total_trades = content.find('div' , {'class' , 'trader_detail_tools_summary'}).find('div' , {'class' : 'panel_inner'}).find_all('div' , {'class' : 'data_value'})[0]\n",
        "    profitability = content.find('div' , {'class' , 'intro'}).find('div' , {'class' : 'data_value'})\n",
        "    result =  {\n",
        "        'trader name' : tradre_name.text.strip() ,\n",
        "        'id' : id ,\n",
        "        'country' : country.text.strip() ,\n",
        "        'in ranking(days)' : in_ranking.text.strip().replace('days',''),\n",
        "        'personal assets (USD)': personal_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'copy traders assets (USD)':copy_traders_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'number of copy traders' : number_of_copy_traders.text.strip(),\n",
        "        'risk' : risk.text.strip().replace('risk','') ,\n",
        "        'total trades' :total_trades.text.strip() ,\n",
        "        'profitability %' : profitability.text.strip().replace(' %' , '')\n",
        "    }\n",
        "    field_names = ['trader name', 'id', 'country' , 'in ranking(days)' , 'personal assets (USD)' , 'copy traders assets (USD)' , 'number of copy traders' , 'risk' , 'total trades' , 'profitability %']\n",
        "    with open(f'{path}/Info about trader.csv', mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "        writer.writeheader()\n",
        "        writer.writerow(result)\n"
      ],
      "metadata": {
        "id": "sv-qw3lx1Lx8"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def List_currency(id:int , path:str):\n",
        "  return pd.read_csv(path)['title'].values.tolist()"
      ],
      "metadata": {
        "id": "t_LPc6yHyHI7"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "traders = pd.read_csv('traders.csv')\n",
        "folder_info = 'traders_info'\n",
        "\n",
        "for index, row in traders.iterrows():\n",
        "    trader_name = row['trader name']\n",
        "    trader_id = row['id']\n",
        "    new_folder_path = f'/content/{folder_info}/{trader_id}'\n",
        "    try:\n",
        "        os.makedirs(new_folder_path, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating directory: {e}\")\n",
        "\n",
        "    popular_tools(id=trader_id, path=new_folder_path)\n",
        "\n",
        "    popular_tools_path = f'{new_folder_path}/popular tools.csv'\n",
        "\n",
        "    list_currency = List_currency(id = trader_id , path = popular_tools_path)\n",
        "\n",
        "    if list_currency:\n",
        "      trading_history(id=trader_id, path=new_folder_path , currency = list_currency )\n",
        "      Get_info_for_trader(id=trader_id, path=new_folder_path)\n",
        "      annual_rates(id=trader_id, path=new_folder_path)\n",
        "      Portfolio_composition(id=trader_id, path=new_folder_path)\n"
      ],
      "metadata": {
        "id": "QEHApJvDgd0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "folder_path = f'/content/{folder_info}'\n",
        "files_name = os.listdir(folder_path)\n",
        "filter_id_1 = []\n",
        "\n",
        "\n",
        "for id in files_name:\n",
        "  history_path = f'/content/{folder_info}/{id}/history.csv'\n",
        "\n",
        "  if os.path.exists(history_path):\n",
        "    history_data = pd.read_csv(history_path)\n",
        "\n",
        "    history_data['profit (USD)'] = pd.to_numeric(history_data['profit (USD)'])\n",
        "    total_profit = history_data['profit (USD)'].sum()\n",
        "    negatev_return = history_data[history_data['profit (USD)']<=0]['profit (USD)'].sum()\n",
        "    positive_return = history_data[history_data['profit (USD)']>=0]['profit (USD)'].sum()\n",
        "    if positive_return > 1000 and negatev_return *-1 < 1000 :\n",
        "      if total_profit > 2000:\n",
        "        filter_id_1.append(id)\n"
      ],
      "metadata": {
        "id": "uVrMcnytMwQl"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_id_2 = []\n",
        "for id in filter_id_1:\n",
        "\n",
        "  annual_rates = f'/content/{folder_info}/{id}/annual rates.csv'\n",
        "\n",
        "  df = pd.read_csv(annual_rates)\n",
        "  df['Date'] = pd.to_datetime(df['Date'])\n",
        "  if df['Profitability %'].mean() >= 120 and df['Profitability %'].min() >= -10:\n",
        "    filter_id_2.append(id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09w-Fz3birag",
        "outputId": "ce194b74-94de-45e2-cde7-2b87757c6f48"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-c95b518f16de>:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "<ipython-input-107-c95b518f16de>:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "<ipython-input-107-c95b518f16de>:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "<ipython-input-107-c95b518f16de>:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n",
            "<ipython-input-107-c95b518f16de>:7: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df['Date'] = pd.to_datetime(df['Date'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filter_id_3 = []\n",
        "for id in filter_id_2:\n",
        "  history_path = f'/content/{folder_info}/{id}/history.csv'\n",
        "  df_history = pd.read_csv(history_path)\n",
        "  df_history['opening time'] = pd.to_datetime(df_history['opening time'], format='%d.%m.%Y %H:%M:%S')\n",
        "  df_history['closing time'] = pd.to_datetime(df_history['closing time'], format='%d.%m.%Y %H:%M:%S')\n",
        "  df_history['duration'] = df_history['closing time'] - df_history['opening time']\n",
        "  if df_history['duration'].max() >= pd.Timedelta(days=3):\n",
        "      filter_id_3.append(id)\n"
      ],
      "metadata": {
        "id": "E8PBusudZuel"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_id_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXrJHzwyTVVq",
        "outputId": "0d182a00-902a-47d1-d23c-9f64cc509552"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sIBa_Wl_m9KV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX01GCgNCK2vXfjfbHaB7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}