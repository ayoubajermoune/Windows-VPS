{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoubajermoune/Windows-VPS/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRk_fIeNbXOg"
      },
      "outputs": [],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "_RUqJd6rfuB1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NpSgC7ajbiX2"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "traders_list = []\n",
        "def dianmic_webset():\n",
        "    url_list = ['https://my.litefinance.org/traders?type=profit', 'https://my.litefinance.org/traders?type=risk']\n",
        "    for url in url_list:\n",
        "        browser.get(url)\n",
        "        for _ in range(1):\n",
        "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(1)\n",
        "        content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "        traders = content.find_all('div' , {'class' : 'card_trader'})\n",
        "        for trader in traders:\n",
        "          profitability = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "          profitability = profitability.text.strip().replace('%', '')\n",
        "          if float(profitability) >= 50:\n",
        "            user_info = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'title'})\n",
        "            id = trader.find('a' , {'class' : 'link'}).get('href')\n",
        "            result = {\n",
        "                'trader name': user_info.text.strip(),\n",
        "                'id': id.strip().replace('/traders/info?id=', ''),\n",
        "                'Profitability (All time) %' : profitability\n",
        "            }\n",
        "            traders_list.append(result)\n",
        "    with open('traders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['trader name', 'id' , 'Profitability (All time) %']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for trader in traders_list:\n",
        "            writer.writerow(trader)\n",
        "dianmic_webset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def annual_rates(id:int,path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        detail_chart_range = content.find('div' , {'class' : 'trader_detail_chart'})\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[0].find_all('div' , {'class' : 'bar'})\n",
        "        Date = []\n",
        "        for bar in bars:\n",
        "          date = bar.find('div' , {'class' : 'data_label'}).text.strip().replace(' ','').replace('\\n' , ' ').split()\n",
        "          date = ' '.join(date[1:3])\n",
        "          result = {\n",
        "              'Date':date\n",
        "          }\n",
        "          Date.append(result)\n",
        "\n",
        "        Profitability = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('%' , '')\n",
        "          result = {\n",
        "              'Profitability %' : value\n",
        "          }\n",
        "          Profitability.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[1].find_all('div' , {'class' : 'bar'})\n",
        "        Risk = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('risk' , '')\n",
        "          result = {\n",
        "              'Risk' : value\n",
        "          }\n",
        "          Risk.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[2].find_all('div' , {'class' : 'bar'})\n",
        "        Copying = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip()\n",
        "          result = {\n",
        "              'Copying' : value\n",
        "          }\n",
        "          Copying.append(result)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Date': Date,\n",
        "            'Risk': Risk,\n",
        "            'Copying': Copying,\n",
        "            'Profitability %': Profitability\n",
        "        })\n",
        "\n",
        "        df['Date'] = df['Date'].apply(lambda x: x['Date'])\n",
        "        df['Risk'] = df['Risk'].apply(lambda x: x['Risk'])\n",
        "        df['Copying'] = df['Copying'].apply(lambda x: x['Copying'])\n",
        "        df['Profitability %'] = df['Profitability %'].apply(lambda x: x['Profitability %'])\n",
        "\n",
        "        df.set_index('Date', inplace=True)\n",
        "\n",
        "        csv_file = f\"{path}/annual rates.csv\"\n",
        "        df.to_csv(csv_file)"
      ],
      "metadata": {
        "id": "r3zqm9aPfniJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def popular_tools(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail_tools = content.find_all('div', {'class': 'panel_inner'})[2]\n",
        "        content_row = trader_detail_tools.find_all('div', {'class': 'content_row_inner'})\n",
        "        detail_tools = []\n",
        "        for row in content_row:\n",
        "          profitable_tag = row.find_all('div', {'class': 'data'})[2].find('div', 'data_value')\n",
        "          profitable = profitable_tag.text.strip().replace('%', '')\n",
        "          if float(profitable) >= 70:\n",
        "            title = row.find('div', {'class': 'title'})\n",
        "            trades = row.find_all('div', {'class': 'data'})[1].find('div', 'data_value')\n",
        "            result = {\n",
        "                'title': title.text.strip().replace('_o', '')[:6],\n",
        "                'trades': trades.text.strip(),\n",
        "                'Profitable %': profitable\n",
        "            }\n",
        "            detail_tools.append(result)\n",
        "\n",
        "        field_names = ['title', 'trades', 'Profitable %']\n",
        "        with open(f'{path}/popular tools.csv', mode='w', newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "            writer.writeheader()\n",
        "            for detail in detail_tools:\n",
        "                writer.writerow(detail)"
      ],
      "metadata": {
        "id": "LmmFje_ynmFC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Portfolio_composition(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail = content.find('div' , {'class' : 'trader_detail_tools_chart_data'}).find_all('div' , {'class' : 'data'})\n",
        "        Detail_name = []\n",
        "        Detail_value = []\n",
        "        for detail in trader_detail:\n",
        "          mareket = detail.find('div' , {'class' : 'data_label'})\n",
        "          precentage = detail.find('div' , {'class' : 'data_value'})\n",
        "          Detail_name.append(f'{mareket.text.strip()} %')\n",
        "          Detail_value.append(precentage.text.strip().replace('%', ''))\n",
        "\n",
        "        with open(f'{path}/Portfolio composition.csv', mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(Detail_name)\n",
        "            writer.writerow(Detail_value)"
      ],
      "metadata": {
        "id": "jDBKmWb4oeHT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "\n",
        "def trading_history(id:int , path:str , currency : list):\n",
        "  url = f'https://my.litefinance.org/traders/trades-history?id={id}'\n",
        "  browser.get(url)\n",
        "  for _ in range(1):\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(1)\n",
        "  content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "  rows = content.find_all('div' , {'class' : 'content_row'})\n",
        "  history = []\n",
        "  for row in rows:\n",
        "    title = row.find_all('div' , {'class' : 'content_col'})[0].find('div' , {'class' : 'title'})\n",
        "    title = title.text.strip()\n",
        "    for symbol in currency:\n",
        "      if symbol == title:\n",
        "        opening_time = row.find_all('div' , {'class' : 'content_col'})[1].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        closing_time = row.find_all('div' , {'class' : 'content_col'})[2].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        action = row.find_all('div' , {'class' : 'content_col'})[3].find('div' , {'class' : 'label'})\n",
        "        volume = row.find_all('div' , {'class' : 'content_col'})[4].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        entry_point = row.find_all('div' , {'class' : 'content_col'})[5].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        exit_point = row.find_all('div' , {'class' : 'content_col'})[6].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        profit = row.find_all('div' , {'class' : 'content_col'})[7].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "        result = {\n",
        "            'title' : title ,\n",
        "            'opening time' : opening_time.text.strip(),\n",
        "            'closing time' :closing_time.text.strip() ,\n",
        "            'action' :action.text.strip() ,\n",
        "            'volume' : volume.text.strip(),\n",
        "            'entry point' : entry_point.text.strip() ,\n",
        "            'exit point' : exit_point.text.strip() ,\n",
        "            'profit (USD)' : profit.text.strip().replace(' USD','')\n",
        "        }\n",
        "        history.append(result)\n",
        "  field_names = ['title' , 'opening time' , 'closing time' , 'action' , 'volume' , 'entry point' , 'exit point' , 'profit (USD)']\n",
        "  with open(f'{path}/history.csv', mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "    writer.writeheader()\n",
        "    for hist in history:\n",
        "        writer.writerow(hist)"
      ],
      "metadata": {
        "id": "z-9STSfUpuZd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def Get_info_for_trader(id:int , path:str):\n",
        "  url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "  r = requests.get(url_trader)\n",
        "  if r.status_code == 200:\n",
        "    content = BeautifulSoup(r.text , 'html.parser')\n",
        "    tradre_name = content.find('div' , {'class' : 'title'})\n",
        "    panel_inner = content.find_all('div' , {'class' : 'panel_inner'})[0]\n",
        "    country = panel_inner.find_all('div' , {'class' : 'data'})[0].find('div' , {'class' : 'data_value'})\n",
        "    in_ranking = panel_inner.find_all('div' , {'class' : 'data'})[1].find('div' , {'class' : 'data_value'})\n",
        "    personal_assets = panel_inner.find_all('div' , {'class' : 'data'})[2].find('div' , {'class' : 'data_value'})\n",
        "    copy_traders_assets = panel_inner.find_all('div' , {'class' : 'data'})[3].find('div' , {'class' : 'data_value'})\n",
        "    number_of_copy_traders = panel_inner.find_all('div' , {'class' : 'data'})[4].find('div' , {'class' : 'data_value'})\n",
        "    risk = panel_inner.find_all('div' , {'class' : 'data'})[5].find('span')\n",
        "    total_trades = content.find('div' , {'class' , 'trader_detail_tools_summary'}).find('div' , {'class' : 'panel_inner'}).find_all('div' , {'class' : 'data_value'})[0]\n",
        "    profitability = content.find('div' , {'class' , 'intro'}).find('div' , {'class' : 'data_value'})\n",
        "    result =  {\n",
        "        'trader name' : tradre_name.text.strip() ,\n",
        "        'id' : id ,\n",
        "        'country' : country.text.strip() ,\n",
        "        'in ranking(days)' : in_ranking.text.strip().replace('days',''),\n",
        "        'personal assets (USD)': personal_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'copy traders assets (USD)':copy_traders_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'number of copy traders' : number_of_copy_traders.text.strip(),\n",
        "        'risk' : risk.text.strip().replace('risk','') ,\n",
        "        'total trades' :total_trades.text.strip() ,\n",
        "        'profitability %' : profitability.text.strip().replace(' %' , '')\n",
        "    }\n",
        "    field_names = ['trader name', 'id', 'country' , 'in ranking(days)' , 'personal assets (USD)' , 'copy traders assets (USD)' , 'number of copy traders' , 'risk' , 'total trades' , 'profitability %']\n",
        "    with open(f'{path}/Info about trader.csv', mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "        writer.writeheader()\n",
        "        writer.writerow(result)\n"
      ],
      "metadata": {
        "id": "sv-qw3lx1Lx8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def List_currency(id:int , path:str):\n",
        "  return pd.read_csv(path)['title'].values.tolist()"
      ],
      "metadata": {
        "id": "t_LPc6yHyHI7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "traders = pd.read_csv('traders.csv')\n",
        "\n",
        "for index, row in traders.iterrows():\n",
        "    trader_name = row['trader name']\n",
        "    trader_id = row['id']\n",
        "    new_folder_path = f'/content/traders info/{trader_id}'\n",
        "    try:\n",
        "        os.makedirs(new_folder_path, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating directory: {e}\")\n",
        "\n",
        "    popular_tools(id=trader_id, path=new_folder_path)\n",
        "\n",
        "    popular_tools_path = f'{new_folder_path}/popular tools.csv'\n",
        "    try :\n",
        "      list_currency = List_currency(id = trader_id , path = popular_tools_path)\n",
        "    except:\n",
        "      list_currency = ''\n",
        "\n",
        "    if list_currency:\n",
        "      trading_history(id=trader_id, path=new_folder_path , currency = list_currency )\n",
        "      Get_info_for_trader(id=trader_id, path=new_folder_path)\n",
        "      annual_rates(id=trader_id, path=new_folder_path)\n",
        "      Portfolio_composition(id=trader_id, path=new_folder_path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QEHApJvDgd0F"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/traders info'\n",
        "files_name = os.listdir(folder_path)\n",
        "id_traders = []\n",
        "\n",
        "for id in files_name:\n",
        ""
      ],
      "metadata": {
        "id": "uVrMcnytMwQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder_path = '/content/traders info'\n",
        "files_name = os.listdir(folder_path)\n",
        "id_traders = []\n",
        "\n",
        "#for id in files_name:\n",
        "#  popular_tools = f'{folder_path}/{id}/popular tools.csv'\n",
        "#  list_currency = List_currency(id = id , path = popular_tools)\n",
        "#  if list_currency:\n",
        "#    print(list_currency)\n",
        "\n",
        "\n",
        "print(files_name)\n"
      ],
      "metadata": {
        "id": "waFBVmdMs2WA",
        "outputId": "f8a8aaf7-ce68-4605-c824-516e326c4f47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['953272', '1003663', '1177279', '1850567', '1582212', '1840700', '2219194', '1411219', '2219860', '1219691', '968181', '2242731', '2826138', '671915', '2290559', '780927', '858979', '753248', '1679829', '1120932', '941691', '1256561', '1216727', '1315262', '956079', '2283539', '1022035', '1184848', '1395992', '964460', '9490', '1263305', '2513359', '3172785', '1939365', '2210431', '1215528', '2040949', '1683067', '899372', '1120915', '2524087', '1150932', '1167765', '1240727', '2100953', '2226687', '1441362', '471387', '913896', '1316754', '1976638', '1273817', '1152404', '1534720', '1216657', '2767461', '1120958']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VrcKVvahtRDw"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdchpz7Sh3S+1ZqnwIH93/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}