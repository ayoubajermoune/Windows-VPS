{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayoubajermoune/Windows-VPS/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRk_fIeNbXOg",
        "outputId": "0d684941-e1d5-44fd-c28d-5dcf901a1223"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.19.0)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.25.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.11.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.7)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium-chromedriver is already the newest version (1:85.0.4183.83-0ubuntu2.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install selenium\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "_RUqJd6rfuB1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NpSgC7ajbiX2"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "traders_list = []\n",
        "def dianmic_webset():\n",
        "    url_list = ['https://my.litefinance.org/traders?type=profit', 'https://my.litefinance.org/traders?type=risk']\n",
        "    for url in url_list:\n",
        "        browser.get(url)\n",
        "        for _ in range(1):\n",
        "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(1)\n",
        "        content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "        traders = content.find_all('div' , {'class' : 'card_trader'})\n",
        "        for trader in traders:\n",
        "          profitability = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "          profitability = profitability.text.strip().replace('%', '')\n",
        "          if float(profitability) >= 10:\n",
        "            user_info = trader.find('div' , {'class' : 'user_info'}).find('div' , {'class' : 'title'})\n",
        "            id = trader.find('a' , {'class' : 'link'}).get('href')\n",
        "            result = {\n",
        "                'trader name': user_info.text.strip(),\n",
        "                'id': id.strip().replace('/traders/info?id=', ''),\n",
        "                'Profitability (All time) %' : profitability\n",
        "            }\n",
        "            traders_list.append(result)\n",
        "    with open('traders.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        fieldnames = ['trader name', 'id' , 'Profitability (All time) %']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        for trader in traders_list:\n",
        "            writer.writerow(trader)\n",
        "dianmic_webset()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GIY87wNfFK9"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def annual_rates(id:int,path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        detail_chart_range = content.find('div' , {'class' : 'trader_detail_chart'})\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[0].find_all('div' , {'class' : 'bar'})\n",
        "        Date = []\n",
        "        for bar in bars:\n",
        "          date = bar.find('div' , {'class' : 'data_label'}).text.strip().replace(' ','').replace('\\n' , ' ').split()\n",
        "          date = ' '.join(date[1:3])\n",
        "          result = {\n",
        "              'Date':date\n",
        "          }\n",
        "          Date.append(result)\n",
        "\n",
        "        Profitability = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('%' , '')\n",
        "          result = {\n",
        "              'Profitability %' : value\n",
        "          }\n",
        "          Profitability.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[1].find_all('div' , {'class' : 'bar'})\n",
        "        Risk = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip().replace('risk' , '')\n",
        "          result = {\n",
        "              'Risk' : value\n",
        "          }\n",
        "          Risk.append(result)\n",
        "\n",
        "        bars = content.find_all('div' , {'class' : 'bars'})[2].find_all('div' , {'class' : 'bar'})\n",
        "        Copying = []\n",
        "        for bar in bars:\n",
        "          value = bar.find('div' , {'class' : 'data_value'}).text.strip()\n",
        "          result = {\n",
        "              'Copying' : value\n",
        "          }\n",
        "          Copying.append(result)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Date': Date,\n",
        "            'Risk': Risk,\n",
        "            'Copying': Copying,\n",
        "            'Profitability %': Profitability\n",
        "        })\n",
        "\n",
        "        # Format Date column\n",
        "        df['Date'] = df['Date'].apply(lambda x: x['Date'])\n",
        "        df['Risk'] = df['Risk'].apply(lambda x: x['Risk'])\n",
        "        df['Copying'] = df['Copying'].apply(lambda x: x['Copying'])\n",
        "        df['Profitability %'] = df['Profitability %'].apply(lambda x: x['Profitability %'])\n",
        "\n",
        "\n",
        "        # Set Date as index\n",
        "        df.set_index('Date', inplace=True)\n",
        "\n",
        "        # Write DataFrame to CSV\n",
        "        csv_file = f\"{path}/annual rates.csv\"\n",
        "        df.to_csv(csv_file)\n"
      ],
      "metadata": {
        "id": "r3zqm9aPfniJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def popular_tools(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail_tools = content.find_all('div', {'class': 'panel_inner'})[2]\n",
        "        content_row = trader_detail_tools.find_all('div', {'class': 'content_row_inner'})\n",
        "        detail_tools = []\n",
        "        for row in content_row:\n",
        "            title = row.find('div', {'class': 'title'})\n",
        "            trades = row.find_all('div', {'class': 'data'})[1].find('div', 'data_value')\n",
        "            profitable = row.find_all('div', {'class': 'data'})[2].find('div', 'data_value')\n",
        "            result = {\n",
        "                'title': title.text.strip().replace('_o', ''),\n",
        "                'trades': trades.text.strip(),\n",
        "                'Profitable %': profitable.text.strip().replace('%', '')\n",
        "            }\n",
        "            detail_tools.append(result)\n",
        "\n",
        "        field_names = ['title', 'trades', 'Profitable %']\n",
        "        with open(f'{path}/popular tools.csv', mode='w', newline='') as file:\n",
        "            writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "            writer.writeheader()\n",
        "            for detail in detail_tools:\n",
        "                writer.writerow(detail)"
      ],
      "metadata": {
        "id": "LmmFje_ynmFC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Portfolio_composition(id:int , path:str):\n",
        "    url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "    r = requests.get(url_trader)\n",
        "    if r.status_code == 200:\n",
        "        content = BeautifulSoup(r.text, 'html.parser')\n",
        "        trader_detail = content.find('div' , {'class' : 'trader_detail_tools_chart_data'}).find_all('div' , {'class' : 'data'})\n",
        "        Detail_name = []\n",
        "        Detail_value = []\n",
        "        for detail in trader_detail:\n",
        "          mareket = detail.find('div' , {'class' : 'data_label'})\n",
        "          precentage = detail.find('div' , {'class' : 'data_value'})\n",
        "          Detail_name.append(f'{mareket.text.strip()} %')\n",
        "          Detail_value.append(precentage.text.strip().replace('%', ''))\n",
        "\n",
        "        with open(f'{path}/Portfolio composition.csv', mode='w', newline='') as file:\n",
        "            writer = csv.writer(file)\n",
        "            writer.writerow(Detail_name)\n",
        "            writer.writerow(Detail_value)"
      ],
      "metadata": {
        "id": "jDBKmWb4oeHT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "import time\n",
        "\n",
        "options = Options()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome(options=options)\n",
        "\n",
        "def trading_history(id:int , path:str):\n",
        "  url = f'https://my.litefinance.org/traders/trades-history?id={id}'\n",
        "  browser.get(url)\n",
        "  for _ in range(1):\n",
        "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    time.sleep(1)\n",
        "  content = BeautifulSoup(browser.page_source , 'html.parser')\n",
        "  rows = content.find_all('div' , {'class' : 'content_row'})\n",
        "  history = []\n",
        "  for row in rows:\n",
        "    title = row.find_all('div' , {'class' : 'content_col'})[0].find('div' , {'class' : 'title'})\n",
        "    opening_time = row.find_all('div' , {'class' : 'content_col'})[1].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    closing_time = row.find_all('div' , {'class' : 'content_col'})[2].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    action = row.find_all('div' , {'class' : 'content_col'})[3].find('div' , {'class' : 'label'})\n",
        "    volume = row.find_all('div' , {'class' : 'content_col'})[4].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    entry_point = row.find_all('div' , {'class' : 'content_col'})[5].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    exit_point = row.find_all('div' , {'class' : 'content_col'})[6].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    profit = row.find_all('div' , {'class' : 'content_col'})[7].find('div' , {'class' : 'data'}).find('div' , {'class' : 'data_value'})\n",
        "    result = {\n",
        "        'title' : title.text.strip() ,\n",
        "        'opening time' : opening_time.text.strip(),\n",
        "        'closing time' :closing_time.text.strip() ,\n",
        "        'action' :action.text.strip() ,\n",
        "        'volume' : volume.text.strip(),\n",
        "        'entry point' : entry_point.text.strip() ,\n",
        "        'exit point' : exit_point.text.strip() ,\n",
        "        'profit (USD)' : profit.text.strip().replace(' USD','')\n",
        "    }\n",
        "    history.append(result)\n",
        "  field_names = ['title' , 'opening time' , 'closing time' , 'action' , 'volume' , 'entry point' , 'exit point' , 'profit (USD)']\n",
        "  with open(f'{path}/history.csv', mode='w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "    writer.writeheader()\n",
        "    for hist in history:\n",
        "        writer.writerow(hist)"
      ],
      "metadata": {
        "id": "z-9STSfUpuZd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "def Get_info_for_trader(id:int , path:str):\n",
        "  url_trader = f'https://my.litefinance.org/traders/info?id={id}'\n",
        "  r = requests.get(url_trader)\n",
        "  if r.status_code == 200:\n",
        "    content = BeautifulSoup(r.text , 'html.parser')\n",
        "    tradre_name = content.find('div' , {'class' : 'title'})\n",
        "    panel_inner = content.find_all('div' , {'class' : 'panel_inner'})[0]\n",
        "    country = panel_inner.find_all('div' , {'class' : 'data'})[0].find('div' , {'class' : 'data_value'})\n",
        "    in_ranking = panel_inner.find_all('div' , {'class' : 'data'})[1].find('div' , {'class' : 'data_value'})\n",
        "    personal_assets = panel_inner.find_all('div' , {'class' : 'data'})[2].find('div' , {'class' : 'data_value'})\n",
        "    copy_traders_assets = panel_inner.find_all('div' , {'class' : 'data'})[3].find('div' , {'class' : 'data_value'})\n",
        "    number_of_copy_traders = panel_inner.find_all('div' , {'class' : 'data'})[4].find('div' , {'class' : 'data_value'})\n",
        "    risk = panel_inner.find_all('div' , {'class' : 'data'})[5].find('span')\n",
        "    total_trades = content.find('div' , {'class' , 'trader_detail_tools_summary'}).find('div' , {'class' : 'panel_inner'}).find_all('div' , {'class' : 'data_value'})[0]\n",
        "    profitability = content.find('div' , {'class' , 'intro'}).find('div' , {'class' : 'data_value'})\n",
        "    result =  {\n",
        "        'trader name' : tradre_name.text.strip() ,\n",
        "        'id' : id ,\n",
        "        'country' : country.text.strip() ,\n",
        "        'in ranking(days)' : in_ranking.text.strip().replace('days',''),\n",
        "        'personal assets (USD)': personal_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'copy traders assets (USD)':copy_traders_assets.text.strip().replace('USD','').replace('~','').replace(' ',''),\n",
        "        'number of copy traders' : number_of_copy_traders.text.strip(),\n",
        "        'risk' : risk.text.strip().replace('risk','') ,\n",
        "        'total trades' :total_trades.text.strip() ,\n",
        "        'profitability %' : profitability.text.strip().replace(' %' , '')\n",
        "    }\n",
        "    field_names = ['trader name', 'id', 'country' , 'in ranking(days)' , 'personal assets (USD)' , 'copy traders assets (USD)' , 'number of copy traders' , 'risk' , 'total trades' , 'profitability %']\n",
        "    with open(f'{path}/Info about trader.csv', mode='w', newline='') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=field_names)\n",
        "        writer.writeheader()\n",
        "        writer.writerow(result)\n"
      ],
      "metadata": {
        "id": "sv-qw3lx1Lx8"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "traders = pd.read_csv('traders.csv')\n",
        "\n",
        "for index, row in traders.iterrows():\n",
        "    trader_name = row['trader name']\n",
        "    trader_id = row['id']\n",
        "    new_folder_path = f'/content/traders_info/{trader_id}'\n",
        "    try:\n",
        "        os.makedirs(new_folder_path, exist_ok=True)\n",
        "    except OSError as e:\n",
        "        print(f\"Error creating directory: {e}\")\n",
        "\n",
        "\n",
        "    Get_info_for_trader(id=trader_id, path=new_folder_path)\n",
        "    annual_rates(id=trader_id, path=new_folder_path)\n",
        "    popular_tools(id=trader_id, path=new_folder_path)\n",
        "    Portfolio_composition(id=trader_id, path=new_folder_path)\n",
        "    trading_history(id=trader_id, path=new_folder_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "QEHApJvDgd0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "traders = pd.read_csv('traders.csv')\n",
        "\n",
        "for index, row in traders.iterrows():\n",
        "    trader_name = row['trader name']\n",
        "    trader_id = row['id']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-btXA5oHgrSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "OSWaebbn2-4P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPcJU8yLvSHwzMcuwU0OW2c",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}